{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup (path, imports, helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Any\n",
    "\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "REPO_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"..\"))\n",
    "\n",
    "if REPO_ROOT not in sys.path:\n",
    "    sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "DATASET_PATH = os.path.join(REPO_ROOT, \"data\", \"farmers-protest-tweets-2021-2-4.json\")\n",
    "assert os.path.exists(DATASET_PATH), f\"Dataset not found at: {DATASET_PATH}\"\n",
    "\n",
    "# Import challenge functions\n",
    "from src.q1_time import q1_time\n",
    "from src.q1_memory import q1_memory\n",
    "\n",
    "from src.q2_time import q2_time\n",
    "from src.q2_memory import q2_memory\n",
    "\n",
    "from src.q3_time import q3_time\n",
    "from src.q3_memory import q3_memory\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BenchResult:\n",
    "    name: str\n",
    "    mean_s: float\n",
    "    sd_s: float\n",
    "    mean_peak_mib: float\n",
    "    sd_peak_mib: float\n",
    "    result_preview: Any\n",
    "\n",
    "def bench(fn: Callable[[str], Any], path: str, name: str, repeats: int = 1) -> BenchResult:\n",
    "    \"\"\"\n",
    "    Measures wall-clock time and peak RSS delta (MiB) using memory_profiler.\n",
    "\n",
    "    - repeats: number of independent runs.\n",
    "    - reports mean ¬± standard deviation for time and peak RSS delta across runs.\n",
    "    \"\"\"\n",
    "    times = []\n",
    "    peaks = []\n",
    "    last_out = None\n",
    "\n",
    "    for _ in range(repeats):\n",
    "        gc.collect()\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        mem_trace, out = memory_usage((fn, (path,)), retval=True, interval=0.05, timeout=None)\n",
    "        t1 = time.perf_counter()\n",
    "\n",
    "        last_out = out\n",
    "        times.append(t1 - t0)\n",
    "        peaks.append(max(mem_trace) - min(mem_trace))  # delta MiB during this call\n",
    "\n",
    "    # compute stats (stdev requires at least 2 samples)\n",
    "    mean_s = sum(times) / len(times)\n",
    "    sd_s = (sum((x - mean_s) ** 2 for x in times) / (len(times) - 1)) ** 0.5 if len(times) > 1 else 0.0\n",
    "\n",
    "    mean_peak = sum(peaks) / len(peaks)\n",
    "    sd_peak = (sum((x - mean_peak) ** 2 for x in peaks) / (len(peaks) - 1)) ** 0.5 if len(peaks) > 1 else 0.0\n",
    "\n",
    "    preview = last_out[:3] if isinstance(last_out, list) else last_out\n",
    "\n",
    "    return BenchResult(\n",
    "        name=name,\n",
    "        mean_s=float(mean_s),\n",
    "        sd_s=float(sd_s),\n",
    "        mean_peak_mib=float(mean_peak),\n",
    "        sd_peak_mib=float(sd_peak),\n",
    "        result_preview=preview,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "This notebook reports the Python/runtime environment to make results comparable across machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.3 (tags/v3.13.3:6280bb5, Apr  8 2025, 14:47:33) [MSC v.1943 64 bit (AMD64)]\n",
      "Platform: Windows-11-10.0.26100-SP0\n",
      "emoji: 2.10.0\n",
      "pandas: 2.3.3\n",
      "memory_profiler: 0.61.0\n"
     ]
    }
   ],
   "source": [
    "import sys, platform\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import memory_profiler\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"emoji:\", getattr(emoji, \"__version__\", \"unknown\"))\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"memory_profiler:\", getattr(memory_profiler, \"__version__\", \"unknown\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer Challenge ‚Äî Benchmark Notebook\n",
    "\n",
    "## Dataset\n",
    "- Format: NDJSON (one JSON object per line).\n",
    "- Path used in this notebook: `data/farmers-protest-tweets-2021-2-4.json`.\n",
    "\n",
    "## Field assumptions (based on the dataset structure)\n",
    "- **Tweet text** for Q2: Use the canonical `content` field.\n",
    "- **Mentions** for Q3: Treat `mentionedUsers` as the canonical structured signal for mentions (when present).\n",
    "\n",
    "These assumptions reduce ambiguity and make results reproducible across environments.\n",
    "\n",
    "## Benchmark methodology\n",
    "The benchmark reports:\n",
    "- **Wall-clock time** (seconds) using `time.perf_counter()`.\n",
    "- **Peak memory delta (MiB)** during the function call using `memory_profiler.memory_usage()`:\n",
    "  - Take `max(trace) - min(trace)` as an approximation of incremental RSS during execution.\n",
    "\n",
    "To reduce noise:\n",
    "- Run each function **N times** (default: `repeats=5`) and report **mean ¬± standard deviation** for time and memory.\n",
    "- Call `gc.collect()` before each run.\n",
    "\n",
    "Limitations:\n",
    "- RSS-based memory measurements vary by OS and Python allocator behavior. Values are intended for relative comparisons within the same environment.\n",
    "\n",
    "Notes on interpretation:\n",
    "- RSS deltas can be **near-zero** or differ by only a few KB due to allocator reuse (pymalloc), fragmentation, and OS behavior.\n",
    "- Therefore, memory-oriented variants are justified primarily by **design choices** (streaming iteration / bounded aggregation domains), not by tiny RSS deltas.\n",
    "\n",
    "## Approach overview \n",
    "\n",
    "### Q1 ‚Äî Top dates and most active user per date\n",
    "**Inputs used:**\n",
    "- `record[\"date\"]` (ISO datetime)\n",
    "- `record[\"user\"][\"username\"]`\n",
    "\n",
    "**Outputs:**\n",
    "- Top 10 dates by tweet count.\n",
    "- For each selected date, the most active user (with deterministic tie-breaking).\n",
    "\n",
    "**q1_time**\n",
    "- Single pass; builds a full `date -> {user -> count}` map for all dates.\n",
    "- Pros: minimal post-processing, straightforward selection.\n",
    "- Cons: higher memory (stores per-user counts for every date).\n",
    "\n",
    "**q1_time ‚Äî stages**\n",
    "1) **Streaming read + parsing:** iterate NDJSON lines; ignore empty/malformed JSON lines.\n",
    "2) **Normalization:** parse `date` to a `datetime.date`; extract `username`.\n",
    "3) **Aggregation:** update `date -> {user -> count}` for all dates.\n",
    "4) **Selection:** compute top-10 dates by tweet count.\n",
    "5) **Per-date winner:** for each selected date, choose the max count user; break ties lexicographically.\n",
    "\n",
    "**q1_memory**\n",
    "- Two passes:\n",
    "  1) Count tweets per date only.\n",
    "  2) For the top-10 dates, count users and select most active.\n",
    "- Pros: lower memory peak by restricting per-user counting to the top-10 dates.\n",
    "- Cons: reads the dataset twice (more I/O).\n",
    "\n",
    "**q1_memory ‚Äî stages**\n",
    "1) **Pass 1 (date volume only):** streaming read; count tweets per `date` only.\n",
    "2) **Top dates selection:** identify top-10 dates by tweet count.\n",
    "3) **Pass 2 (bounded per-user counts):** streaming read again; only for records whose `date` is in top-10, update `user -> count`.\n",
    "4) **Per-date winner:** select most active user per date with deterministic tie-breaking.\n",
    "\n",
    "\n",
    "### Q2 ‚Äî Top emojis\n",
    "**Input used:**\n",
    "- `record[\"content\"]`\n",
    "\n",
    "**Outputs:**\n",
    "- Top 10 emojis by total usage across all tweets, ordered deterministically (count desc, emoji asc).\n",
    "\n",
    "**q2_time:** \n",
    "- uses `emoji.emoji_list(text)`, which materializes a list of emoji matches per record.\n",
    "\n",
    "**q2_time ‚Äî stages**\n",
    "1) **Streaming read + parsing:** iterate NDJSON; ignore empty/malformed JSON lines.\n",
    "2) **Text extraction:** use `content` as the canonical text.\n",
    "3) **Emoji extraction:** call `emoji.emoji_list(text)` (materializes a list of matches per record).\n",
    "4) **Aggregation:** increment global counts per emoji.\n",
    "5) **Selection:** sort counts (desc) and emoji (asc), take top-10.\n",
    "\n",
    "**q2_memory:** \n",
    "- uses `emoji.analyze(text)` to stream emoji tokens without per-record list materialization.\n",
    "\n",
    "**q2_memory ‚Äî stages**\n",
    "1) **Streaming read + parsing:** iterate NDJSON; ignore empty/malformed JSON lines.\n",
    "2) **Text extraction:** use `content` as the canonical text.\n",
    "3) **Emoji streaming:** iterate `emoji.analyze(text)` tokens (no per-record list materialization).\n",
    "4) **Aggregation:** increment global counts per emoji token.\n",
    "5) **Selection:** deterministic top-10.\n",
    "\n",
    "Given that memory is measured as RSS delta, small differences (KB-range) are often dominated by allocator noise. The memory optimization is primarily justified mechanically by streaming iteration.\n",
    "\n",
    "\n",
    "### Q3 ‚Äî Top mentioned users\n",
    "**Inputs used:**\n",
    "- Primary: `record[\"mentionedUsers\"]` (structured list of mentioned usernames)\n",
    "- Secondary (time only): parse `record[\"content\"]` with a mention regex if `mentionedUsers` is missing/empty.\n",
    "\n",
    "**Outputs:**\n",
    "- Top 10 mentioned usernames across the dataset (count desc, username asc).\n",
    "\n",
    "**q3_time**\n",
    "- Uses `mentionedUsers` as primary (fast, structured).\n",
    "- Falls back to regex parsing of `content` only when structured mentions are missing/empty (higher recall).\n",
    "\n",
    "**q3_time ‚Äî stages**\n",
    "1) **Streaming read + parsing:** iterate NDJSON; ignore empty/malformed JSON lines.\n",
    "2) **Canonical extraction:** if `mentionedUsers` exists and is non-empty, count those usernames directly.\n",
    "3) **Fallback extraction:** if `mentionedUsers` is missing/empty, apply regex to `content` to increase recall.\n",
    "4) **Aggregation:** increment global counts per mentioned username.\n",
    "5) **Selection:** deterministic top-10.\n",
    "\n",
    "**q3_memory**\n",
    "- Uses only `mentionedUsers` as the canonical signal.\n",
    "- Rationale: minimizes temporary allocations and avoids ambiguous false positives from raw-text parsing (emails/URLs/text artifacts).\n",
    "\n",
    "**q3_memory ‚Äî stages**\n",
    "1) **Streaming read + parsing:** iterate NDJSON; ignore empty/malformed JSON lines.\n",
    "2) **Canonical-only extraction:** count only `mentionedUsers` usernames.\n",
    "3) **Aggregation + selection:** deterministic top-10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correctness parity checks (time vs memory variants must match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 time (preview): [(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur')]\n",
      "Q1 memory (preview): [(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur')]\n",
      "Q2 time (preview): [('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972)]\n",
      "Q2 memory (preview): [('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972)]\n",
      "Q3 time (preview): [('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644)]\n",
      "Q3 memory (preview): [('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644)]\n",
      "OK: time vs memory variants match for Q1/Q2/Q3.\n"
     ]
    }
   ],
   "source": [
    "q1_time_res = q1_time(DATASET_PATH)\n",
    "q1_memory_res = q1_memory(DATASET_PATH)\n",
    "q2_time_res = q2_time(DATASET_PATH)\n",
    "q2_memory_res = q2_memory(DATASET_PATH)\n",
    "q3_time_res = q3_time(DATASET_PATH)\n",
    "q3_memory_res = q3_memory(DATASET_PATH)\n",
    "\n",
    "print(\"Q1 time (preview):\", q1_time_res[:3])\n",
    "print(\"Q1 memory (preview):\", q1_memory_res[:3])\n",
    "\n",
    "print(\"Q2 time (preview):\", q2_time_res[:3])\n",
    "print(\"Q2 memory (preview):\", q2_memory_res[:3])\n",
    "\n",
    "print(\"Q3 time (preview):\", q3_time_res[:3])\n",
    "print(\"Q3 memory (preview):\", q3_memory_res[:3])\n",
    "\n",
    "assert q1_time_res == q1_memory_res, \"Q1 mismatch between time and memory variants\"\n",
    "assert q2_time_res == q2_memory_res, \"Q2 mismatch between time and memory variants\"\n",
    "assert q3_time_res == q3_memory_res, \"Q3 mismatch between time and memory variants\"\n",
    "print(\"OK: time vs memory variants match for Q1/Q2/Q3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark (time and memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BenchResult(name='Q1 time', mean_s=3.6089521399931983, sd_s=0.27005408844711903, mean_peak_mib=0.9296875, sd_peak_mib=0.44858991312361224, result_preview=[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur')]),\n",
       " BenchResult(name='Q1 memory', mean_s=6.18068759997841, sd_s=0.1768491259211185, mean_peak_mib=1.20390625, sd_peak_mib=0.6073270374115529, result_preview=[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur')]),\n",
       " BenchResult(name='Q2 time', mean_s=10.192137160012498, sd_s=0.17357495320130495, mean_peak_mib=0.01171875, sd_peak_mib=0.013531646934131853, result_preview=[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972)]),\n",
       " BenchResult(name='Q2 memory', mean_s=11.365693859988824, sd_s=0.08328115398665827, mean_peak_mib=0.0, sd_peak_mib=0.0, result_preview=[('üôè', 5049), ('üòÇ', 3072), ('üöú', 2972)]),\n",
       " BenchResult(name='Q3 time', mean_s=3.215019959991332, sd_s=0.08963572808988862, mean_peak_mib=0.05, sd_peak_mib=0.058489490575764976, result_preview=[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644)]),\n",
       " BenchResult(name='Q3 memory', mean_s=3.2170695800101385, sd_s=0.11694284164662654, mean_peak_mib=0.0, sd_peak_mib=0.0, result_preview=[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644)])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks = [\n",
    "    (q1_time,   \"Q1 time\"),\n",
    "    (q1_memory, \"Q1 memory\"),\n",
    "    (q2_time,   \"Q2 time\"),\n",
    "    (q2_memory, \"Q2 memory\"),\n",
    "    (q3_time,   \"Q3 time\"),\n",
    "    (q3_memory, \"Q3 memory\"),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for fn, name in benchmarks:\n",
    "    r = bench(fn, DATASET_PATH, name=name, repeats=5) \n",
    "    results.append(r)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>time_mean_s</th>\n",
       "      <th>time_sd_s</th>\n",
       "      <th>peak_mem_mean_mib</th>\n",
       "      <th>peak_mem_sd_mib</th>\n",
       "      <th>result_preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1 memory</td>\n",
       "      <td>6.1807</td>\n",
       "      <td>0.1768</td>\n",
       "      <td>1.204</td>\n",
       "      <td>0.607</td>\n",
       "      <td>[(2021-02-12, RanbirS00614606), (2021-02-13, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1 time</td>\n",
       "      <td>3.6090</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.449</td>\n",
       "      <td>[(2021-02-12, RanbirS00614606), (2021-02-13, M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q2 memory</td>\n",
       "      <td>11.3657</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[(üôè, 5049), (üòÇ, 3072), (üöú, 2972)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q2 time</td>\n",
       "      <td>10.1921</td>\n",
       "      <td>0.1736</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.014</td>\n",
       "      <td>[(üôè, 5049), (üòÇ, 3072), (üöú, 2972)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q3 memory</td>\n",
       "      <td>3.2171</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[(narendramodi, 2265), (Kisanektamorcha, 1840)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3 time</td>\n",
       "      <td>3.2150</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.058</td>\n",
       "      <td>[(narendramodi, 2265), (Kisanektamorcha, 1840)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        task  time_mean_s  time_sd_s  peak_mem_mean_mib  peak_mem_sd_mib  \\\n",
       "1  Q1 memory       6.1807     0.1768              1.204            0.607   \n",
       "0    Q1 time       3.6090     0.2701              0.930            0.449   \n",
       "3  Q2 memory      11.3657     0.0833              0.000            0.000   \n",
       "2    Q2 time      10.1921     0.1736              0.012            0.014   \n",
       "5  Q3 memory       3.2171     0.1169              0.000            0.000   \n",
       "4    Q3 time       3.2150     0.0896              0.050            0.058   \n",
       "\n",
       "                                      result_preview  \n",
       "1  [(2021-02-12, RanbirS00614606), (2021-02-13, M...  \n",
       "0  [(2021-02-12, RanbirS00614606), (2021-02-13, M...  \n",
       "3                  [(üôè, 5049), (üòÇ, 3072), (üöú, 2972)]  \n",
       "2                  [(üôè, 5049), (üòÇ, 3072), (üöú, 2972)]  \n",
       "5  [(narendramodi, 2265), (Kisanektamorcha, 1840)...  \n",
       "4  [(narendramodi, 2265), (Kisanektamorcha, 1840)...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([{\n",
    "    \"task\": r.name,\n",
    "    \"time_mean_s\": round(r.mean_s, 4),\n",
    "    \"time_sd_s\": round(r.sd_s, 4),\n",
    "    \"peak_mem_mean_mib\": round(r.mean_peak_mib, 3),\n",
    "    \"peak_mem_sd_mib\": round(r.sd_peak_mib, 3),\n",
    "    \"result_preview\": r.result_preview\n",
    "} for r in results]).sort_values(\"task\")\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion\n",
    "\n",
    "### Q1\n",
    "The time-oriented implementation (`q1_time`) is faster than the memory-oriented version, as expected due to the two-pass strategy in `q1_memory`.\n",
    "\n",
    "In this dataset, the RSS delta does not show a memory advantage for `q1_memory`. This is consistent with the fact that the memory-oriented approach provides a worst-case bounding strategy, while observed gains depend on the data distribution and the coarseness of RSS-based measurement.\n",
    "\n",
    "This outcome is expected given the dataset characteristics:\n",
    "- The number of distinct dates and per-date user distributions do not cause the full `date ‚Üí user ‚Üí count` structure to grow excessively.\n",
    "- As a result, the two-pass strategy in `q1_memory` does not yield a memory advantage here, while it incurs additional I/O and processing cost.\n",
    "\n",
    "This highlights an important point: **memory-oriented designs provide worst-case guarantees, but their benefits depend on data distribution**.\n",
    "\n",
    "### Q2\n",
    "Runtime is dominated by emoji parsing. In this run, the memory-oriented variant is slightly slower, which is consistent with different constant factors between `emoji_list()` and `analyze()`.\n",
    "\n",
    "The memory-oriented variant avoids per-record list materialization by streaming emoji tokens via `emoji.analyze(text)`. For RSS delta, small differences (including near-zero values) may be dominated by allocator/OS behavior; the memory justification is therefore mechanical (streaming iteration) rather than marginal RSS deltas.\n",
    "\n",
    "This confirms that:\n",
    "- Both approaches share the same asymptotic complexity.\n",
    "- The memory-oriented implementation avoids per-record list materialization by design via streaming iteration (`emoji.analyze`).\n",
    "\n",
    "For RSS delta, the observed differences (including near-zero values) may be dominated by allocator/OS behavior; consequently, the memory justification is primarily mechanical (streaming iteration) rather than marginal RSS deltas.\n",
    "\n",
    "### Q3\n",
    "Runtime differences between the two versions are negligible.\n",
    "The time-oriented implementation includes a fallback to parse mentions from raw text, but in practice this path is rarely triggered because the dataset provides structured `mentionedUsers` metadata.\n",
    "\n",
    "The memory-oriented version avoids text parsing entirely and relies only on the canonical structured signal, resulting in the lowest observed memory overhead.\n",
    "\n",
    "### Overall\n",
    "Across all questions:\n",
    "- Differences between *time* and *memory* implementations are driven by **engineering tradeoffs and constant factors**, not asymptotic complexity.\n",
    "- Dataset characteristics strongly influence whether a memory-oriented strategy yields visible gains.\n",
    "- Explicitly separating these approaches makes the tradeoffs transparent and reproducible.\n",
    "\n",
    "## Conclusions\n",
    "- Q1 shows a clear tradeoff: the memory variant bounds the aggregation domain (top dates) at the cost of a second pass.\n",
    "- Q2 runtime is dominated by emoji parsing; the memory-oriented variant avoids per-record list materialization by design, with modest differences in runtime driven by constant factors.\n",
    "- Q3 memory variant can be faster by relying only on canonical structured mentions and avoiding regex fallback.\n",
    "\n",
    "Benchmarks confirm correctness parity across variants; RSS deltas are reported as a coarse proxy and may be near-zero due to allocator/OS effects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
